{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL3OqFKZ9dFg"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCZTzUdIcE75",
        "outputId": "f9484473-cea4-424e-9cab-c894b3c7f2dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd '/content/drive/MyDrive/Colab Notebooks/SL_TRUST/cnn trust/update'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aHJjVxa5fkG",
        "outputId": "7bcd1b33-1922-4a50-e049-cc523dda3a82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/SL_TRUST/cnn trust/update\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from copy_cifar10_with_attack import *"
      ],
      "metadata": {
        "id": "fSrfE5B1bZWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzLKpmZICaWN",
        "outputId": "5083e9ca-4097-42cc-beb3-abb54f94d8e6"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "from keras.preprocessing.image import img_to_array, array_to_img\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "# Helper libraries\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR0EdgrLCaWR"
      },
      "source": [
        "## Import the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkjPTOuW28xX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "025f29d0-947a-4251-fa1e-5b0fe103cecb"
      },
      "source": [
        "# # Cifar10, Cifar 100, FashionMNIST\n",
        "# fashion_mnist = keras.datasets.fashion_mnist\n",
        "# (train_images, train_label), (test_images, test_label) = fashion_mnist.load_data()\n",
        "# train_images = train_images / 255.0 ##fashion_mnist\n",
        "# test_images= test_images / 255.0 ##fashion_mnist\n",
        "# # train_images=np.stack([train_images]*3, axis=-1)\n",
        "# # test_images=np.stack([test_images]*3, axis=-1)\n",
        "# # train_images = np.asarray([img_to_array(array_to_img(im, scale=False).resize((32,32))) for im in train_images])\n",
        "# # test_images = np.asarray([img_to_array(array_to_img(im, scale=False).resize((32,32))) for im in test_images])\n",
        "\n",
        "fashion_mnist = keras.datasets.cifar10\n",
        "(train_images, train_label), (test_images, test_label) = fashion_mnist.load_data()\n",
        "\n",
        "train_images.shape, train_label.shape, test_images.shape, test_label.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59veuiEZCaW4"
      },
      "source": [
        "## Build the model\n",
        "\n",
        "Building the neural network requires configuring the layers of the model, then compiling the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxLmj4eGAFTL",
        "outputId": "08d0a815-939a-41a4-95ec-15e3ff24c268"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import sklearn\n",
        "from sklearn.metrics import auc, plot_precision_recall_curve\n",
        "\n",
        "model_load = tf.keras.models.load_model('/content/drive/MyDrive/cnn trust/update/parameters/model_cnn_cifar10.h5')\n",
        "model_load.evaluate(test_images, test_label)\n",
        "\n",
        "y_pred = model_load.predict(test_images)\n",
        "m = tf.keras.metrics.AUC(num_thresholds=200)\n",
        "m.update_state(tf.one_hot(test_label[:,0],depth=10), y_pred)\n",
        "auroc = m.result().numpy()\n",
        "\n",
        "y_pred = tf.math.argmax(y_pred,axis=1)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_label, y_pred,average='weighted')\n",
        "\n",
        "precision, recall, f1, auroc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 8s 5ms/step - loss: 0.5219 - accuracy: 0.8527\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8576079966186256, 0.8527, 0.8530323732877543, 0.97981775)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reload model and remove the dense layers"
      ],
      "metadata": {
        "id": "5bkmRsm71m08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "\n",
        "model2= Model(inputs=model_load.input, outputs=model_load.layers[-8].output)\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eAafDVwyu9I",
        "outputId": "bb4b76e0-6ef3-40d6-b009-6ad0eb49186d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_input (InputLayer)   [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " depthwise_conv2d (Depthwise  (None, 32, 32, 96)       960       \n",
            " Conv2D)                                                         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32, 32, 96)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 64)        55360     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " depthwise_conv2d_1 (Depthwi  (None, 16, 16, 64)       640       \n",
            " seConv2D)                                                       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " depthwise_conv2d_2 (Depthwi  (None, 16, 16, 128)      1280      \n",
            " seConv2D)                                                       \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " depthwise_conv2d_3 (Depthwi  (None, 16, 16, 128)      256       \n",
            " seConv2D)                                                       \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 8, 8, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " depthwise_conv2d_4 (Depthwi  (None, 8, 8, 256)        2560      \n",
            " seConv2D)                                                       \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 4, 4, 512)         131584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 4, 4, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " depthwise_conv2d_5 (Depthwi  (None, 4, 4, 512)        1024      \n",
            " seConv2D)                                                       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 715,648\n",
            "Trainable params: 713,408\n",
            "Non-trainable params: 2,240\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##convert images to features"
      ],
      "metadata": {
        "id": "qcnDezJ6vNjf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-X1WJBZWujb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d2004d4-8aa2-4fb6-e795-f075de3b84b9"
      },
      "source": [
        "test_feature = model2.predict(test_images)              \n",
        "train_feature = model2.predict(train_images)\n",
        "train_feature.shape, test_feature.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 4, 4, 512), (10000, 4, 4, 512))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjmSb3IO_2K0",
        "outputId": "41a93461-b78e-4fd8-934a-a25de0c99cd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a new small model for transfer learning"
      ],
      "metadata": {
        "id": "4RYPHOiO1ssm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def intitial_W_x(X):\n",
        "    \"\"\"\n",
        "    Initialize input opinion for caseI.\n",
        "    \n",
        "    \"\"\"\n",
        "    W_dis = np.zeros(X.shape).astype(np.float32)\n",
        "    W_base = W_dis + 0.5\n",
        "    W_x = np.array([X, W_dis, 1 - X, W_base]).astype(np.float32)\n",
        "    W_x = np.moveaxis(W_x, 0, -1)\n",
        "    \n",
        "    return W_x\n",
        "\n",
        "def get_update_matrix(grads_w, grads_b, rs):\n",
        "    \"\"\"\n",
        "    Update the opinion of weight and bias during training process.\n",
        "    grads_w - gradient evidence matrix of weight\n",
        "    grads_b - gradient evidence matrix of bias\n",
        "    rs - positive evidence plus negative evidence\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    W_w = np.array([grads_w/(rs+2),(rs-grads_w)/(rs+2),np.full(grads_w.shape, 2/(rs+2)),\n",
        "                    np.full(grads_w.shape, 0.5)]).astype(np.float32)\n",
        "    W_b = np.array([grads_b/(rs+2), (rs-grads_b)/(rs+2), np.full(grads_b.shape, 2/(rs+2)), \n",
        "                    np.full(grads_b.shape, 0.5)]).astype(np.float32)\n",
        "    W_w = np.moveaxis(W_w, 0, -1)\n",
        "    \n",
        "    return W_w, W_b.swapaxes(0,1)\n",
        "\n",
        "def evidence_collect(y, y_pred):\n",
        "    \"\"\"\n",
        "    Collect positive and negative evidence during the training process.\n",
        "\n",
        "    \"\"\"\n",
        "    r = 0\n",
        "    s = 0\n",
        "    r_list = [0]*10\n",
        "    s_list = [0]*10\n",
        "    \n",
        "    for j in range(len(y_pred)):\n",
        "        for i in range(len(y_pred[0])):\n",
        "            if i == y[j]:\n",
        "                if y_pred[j][i] > 0.5:\n",
        "                    r_list[i]+=1\n",
        "                    r+=1\n",
        "                else:\n",
        "                    s+=1\n",
        "                    s_list[i]+=1\n",
        "            else:\n",
        "                if y_pred[j][i] < 0.1:\n",
        "                    r_list[i]+=1\n",
        "                else:\n",
        "                    s_list[i]+=1\n",
        "                    \n",
        "    y_N_op = []\n",
        "    for i in range(len(r_list)):\n",
        "        y_N_op.append([r_list[i]/(r_list[i]+s_list[i]+2), \n",
        "                       s_list[i]/(r_list[i]+s_list[i]+2), 2/(r_list[i]+s_list[i]+2), 0.5])\n",
        "\n",
        "    \n",
        "    return [r/(r+s+2), s/(r+s+2), 2/(r+s+2), 0.5], y_N_op"
      ],
      "metadata": {
        "id": "dHyzE_zb9ChV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def padding(opinion, kernel_size):\n",
        "    \"\"\"\n",
        "    Trust map padding with maximum unblief mass on the padding cell. \n",
        "    \n",
        "    \"\"\"\n",
        "    image_size = opinion.shape[1]\n",
        "    p = int((kernel_size - 1)/2)\n",
        "    padding_size = int(image_size + 2 * p)\n",
        "    opinion_pad = np.zeros((int(opinion.shape[0]),padding_size,padding_size,int(opinion.shape[-2]),int(opinion.shape[-1])))\n",
        "    opinion_pad[:,:,:,:] = np.array([0.0, 0.99, 0.01, 0.5])\n",
        "    opinion_pad[:,p:p+image_size,p:p+image_size,:,:] = opinion\n",
        "    return opinion_pad\n",
        "\n",
        "def multi(W_x, W_y): \n",
        "    \"\"\"\n",
        "    Multi-sources multiplication Operator \n",
        "\n",
        "    \"\"\"\n",
        "    W_x = W_x.astype(np.float64) \n",
        "    W_y = W_y.astype(np.float64)    \n",
        "    W_b = W_x[0]*W_y[0]+((1-W_x[3])*W_y[3]*W_x[0]*W_y[2]+W_x[3]*(1-W_y[3])*W_y[0]*W_x[2])/(1-W_x[3]*W_y[3])\n",
        "    W_d = W_x[1]+W_y[1]-W_x[1]*W_y[1]\n",
        "    W_u = W_x[2]*W_y[2]+((1-W_y[3])*W_x[0]*W_y[2]+(1-W_x[3])*W_y[0]*W_x[2])/(1-W_x[3]*W_y[3])\n",
        "    W_a = W_x[3]*W_y[3]\n",
        "    return W_b,W_d,W_u,W_a"
      ],
      "metadata": {
        "id": "OGeJsNm-79Nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_single_step_trust(W_x, W_w, W_b): \n",
        "    \"\"\"\n",
        "    Compute the output opinion of one convolutional kernel window.\n",
        "    inputs:\n",
        "    W_x - input opinion (batch size, kernel size, kernel size, channel, 4)\n",
        "    W_w - weight opinion (kernel size, kernel size, channel, filter number, 4)\n",
        "    W_b - bias opinion (filter number, 4)\n",
        "    \n",
        "    \"\"\"    \n",
        "    W_x = W_x.astype(np.float64)   \n",
        "    W_w = W_w.numpy().astype(np.float64) \n",
        "    W_b = W_b.numpy().astype(np.float64) \n",
        "    \n",
        "    filter_number = W_b.shape[0]\n",
        "    batch_size = W_x.shape[0]\n",
        "    fusion_result = []\n",
        "    W_x_expand = np.tile(np.expand_dims(W_x, axis=(4)), [1,1,1,1,filter_number,1])\n",
        "    W_w_expand = np.tile(np.expand_dims(W_w, axis=(0)), [batch_size,1,1,1,1,1])\n",
        "    W_b_expand = np.tile(np.expand_dims(W_b, axis=(0)), [batch_size,1,1])\n",
        "    W_wx = multi(np.transpose(W_x_expand),np.transpose(W_w_expand)) # (4, 32, 3, 5, 5, 50)\n",
        "    fusion_result = avg_fusion(np.asarray(W_wx), np.transpose(W_b_expand))\n",
        "    \n",
        "    return np.transpose(fusion_result[0]),np.transpose(fusion_result[1])\n",
        "\n",
        "def avg_fusion(W_wx, W_b):\n",
        "    \"\"\"\n",
        "    Multi-sources average opinion operator.\n",
        "    W_wx - opinion of input mutiplied with weight opinion (4, filter number, channel, kernel size, kernel size, batch size)\n",
        "    W_b - bias opinion (4, filter number, batch size)\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    W_wx = np.reshape(W_wx, (W_wx.shape[0],W_wx.shape[1], \n",
        "                             W_wx.shape[2]*W_wx.shape[3]*W_wx.shape[4], W_wx.shape[5])).astype(np.float64) # (4, 32, 75, 50)\n",
        "    W_b = W_b.astype(np.float64)\n",
        "    \n",
        "    n_filter = W_b.shape[1]\n",
        "    batch_size = W_wx.shape[-1]\n",
        "    num_para = W_wx.shape[2]\n",
        "    b_wx, u_wx, a_wx = W_wx[0], W_wx[2], W_wx[3]\n",
        "    b_b, u_b, a_b = W_b[0], W_b[2], W_b[3]\n",
        "\n",
        "    u_combine = np.concatenate((u_wx, np.reshape(u_b,(u_b.shape[0], 1, batch_size))), axis=1) # (32, 76, 50)\n",
        "    b_combine = np.concatenate((b_wx, np.reshape(b_b,(b_b.shape[0], 1, batch_size))), axis=1) # (32, 76, 50)\n",
        "    u_combine_recip = (np.zeros(u_combine.shape)+1)/u_combine\n",
        "    \n",
        "    numerator = np.sum(b_combine * u_combine_recip, axis = 1) # (32, 50)\n",
        "    denominator = np.sum(u_combine_recip, axis = (1))\n",
        "    \n",
        "    b_fusion = numerator / denominator\n",
        "    u_fusion = (num_para+1) / denominator\n",
        "    a_fusion = (np.sum(a_wx, axis=(1)) + a_b) / (num_para+1)\n",
        "    \n",
        "    return np.array([b_fusion, 1-b_fusion-u_fusion, u_fusion, a_fusion]).astype(np.float32), (b_fusion + u_fusion * a_fusion).astype(np.float32)"
      ],
      "metadata": {
        "id": "KTxYPCt78UqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_forward(A_prev, W_w, W_b):\n",
        "    \"\"\"\n",
        "    Forward convolutional opinion calculation.\n",
        "    A_prev - feature map from last layer (batch_size, H, W, channel) \n",
        "    W_w - opinion of weight (kernel_size, kernel_size, 3, filter_num, 4)\n",
        "    W_b - opinion of bias (filter_num, 4)\n",
        "\n",
        "    \"\"\"\n",
        "    (batch_size, n_H_prev, n_W_prev, _, _) = A_prev.shape\n",
        "    ( f , f , _, n_C, _) = W_w.shape\n",
        "    stride = 1\n",
        "    pad = 1\n",
        "    A_prev_pad = padding(A_prev,f)\n",
        "\n",
        "    n_H = int(( n_H_prev - f + 2 * pad )/ stride) + 1\n",
        "    n_W = int(( n_W_prev - f + 2 * pad )/ stride) + 1\n",
        " \n",
        "    Z = np.zeros((batch_size, n_H, n_W, n_C, 4)) \n",
        "    Z_trust = np.zeros((batch_size, n_H, n_W, n_C))\n",
        "\n",
        "    for h in range(n_H):                       \n",
        "        for w in range(n_W):                              \n",
        "            vert_start = h * stride        \n",
        "            vert_end = vert_start + f       \n",
        "            horiz_start = w * stride        \n",
        "            horiz_end = horiz_start + f     \n",
        "            a_slice_prev = A_prev_pad[:,vert_start:vert_end,horiz_start:horiz_end,:,:]   \n",
        "            opinion, trust = conv_single_step_trust(a_slice_prev,W_w,W_b)   \n",
        "            Z[:,h,w,:,:] = opinion\n",
        "            Z_trust[:,h,w,:] = trust\n",
        "\n",
        "    return Z, Z_trust"
      ],
      "metadata": {
        "id": "pDsrt2Bd74XD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLayerCONV(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Conv opinion computation layer\n",
        "    \n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(MyLayerCONV, self).__init__()\n",
        "\n",
        "\n",
        "    def call(self, input1, input2, input3):\n",
        "        \n",
        "        Z, Z_trust = conv_forward(input1, input2, input3)\n",
        "           \n",
        "        return Z.astype(np.float32), Z_trust.astype(np.float32)\n"
      ],
      "metadata": {
        "id": "Ym05svph7zja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLayerMaxTrust(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Max-trust fuction layer\n",
        "    A new pooling layer function based on trustworthiness values instead of feature values. \n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(MyLayerMaxTrust, self).__init__()\n",
        "\n",
        "\n",
        "    def call(self, x, opinion, trust):\n",
        "        \"\"\"\n",
        "        x - feature map from last layer (batch, H, W, C)\n",
        "        opinion - corresponding opinion (batch, H, W, C, 4)\n",
        "        trust - corresponding trust (batch, H, W, C)\n",
        "\n",
        "        \"\"\"\n",
        "        trust_mul = np.zeros(x.shape)\n",
        "        image_size = x.shape[1]\n",
        "        opinion_out = np.zeros((opinion.shape[0],int(opinion.shape[1]/2), int(opinion.shape[2]/2),opinion.shape[3], 4)).astype(np.float32)\n",
        "        for i in range(trust.shape[0]):\n",
        "            for k in range(trust.shape[-1]):\n",
        "                input_max = trust[i,:,:,k].reshape((1,trust.shape[1],trust.shape[2],1))\n",
        "                _, argmax = tf.nn.max_pool_with_argmax(input = input_max, ksize = [1, 2, 2, 1],\n",
        "                                                    strides = [1, 2, 2, 1], padding = 'VALID')\n",
        "                argmax_1d = argmax.numpy().flatten()\n",
        "                for j in range(len(argmax_1d)):\n",
        "                    trust_mul[i,int(argmax_1d[j]/image_size),int(argmax_1d[j]%image_size),k] = 1\n",
        "                    opinion_out[i,int(j/int(image_size/2)), int(j%int(image_size/2)),k,:] = opinion[i,int(argmax_1d[j]/image_size),int(argmax_1d[j]%image_size),k,:] \n",
        "\n",
        "        x = x * trust_mul\n",
        "\n",
        "        return x, opinion_out"
      ],
      "metadata": {
        "id": "QofOduO3859D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrustBlock(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.convopinion1 = MyLayerCONV()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(\n",
        "            filters=32,             \n",
        "            kernel_size=[3, 3],\n",
        "            padding='same',\n",
        "            activation=tf.nn.relu   \n",
        "        )\n",
        "        self.maxtrust1 = MyLayerMaxTrust()\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.dense1 = tf.keras.layers.Dense(units=64, activation=tf.nn.relu)\n",
        "        self.dense2 = tf.keras.layers.Dense(units=10, activation=tf.nn.softmax)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        x - 50,32,32,3\n",
        "        W_x - 50,32,32,3,4\n",
        "        \n",
        "        \n",
        "        \"\"\"\n",
        "        X, W_x, W_w1, W_b1 = inputs\n",
        " \n",
        "        opinion1, trust1 = self.convopinion1(W_x, W_w1, W_b1)\n",
        "        x = self.conv1(X)   \n",
        "        x, pooling_opinion1 = self.maxtrust1(x, opinion1, trust1)\n",
        "        x = self.pool1(x)    \n",
        "        x = self.flatten(x) \n",
        "        x = self.dense1(x)    \n",
        "        output = self.dense2(x)                    \n",
        "        return output,pooling_opinion1\n",
        "\n",
        "model_maxtrust = TrustBlock()"
      ],
      "metadata": {
        "id": "_FIOflNIWvjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "batch_size = 128\n",
        "kernelsize = 3\n",
        "filter_num1 = 32\n",
        "# threshold1 = 20\n",
        "# threshold2 = 15\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "sparse_categorical_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "train_acc = []\n",
        "train_loss = []\n",
        "opinion_convlist = []\n",
        "y_update_wb = []\n",
        "y_N_opinion = []"
      ],
      "metadata": {
        "id": "_OuowS8peGSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(train_data, train_label, batch_size):\n",
        "    index = np.random.randint(0, train_data.shape[0], batch_size)\n",
        "    return train_data[index, :], train_label[index]"
      ],
      "metadata": {
        "id": "3SFztC-heLWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch training process\n",
        "num_batches = int(train_images.shape[0] // batch_size * num_epochs)\n",
        "\n",
        "W_w1 = np.array([[[[[0.0, 0.0, 1.0, 0.5] for _ in range(filter_num1)] for _ in range(512)] \n",
        "                  for _ in range(kernelsize)] for _ in range(kernelsize)]).astype(np.float32)\n",
        "\n",
        "W_b1 = np.array([[0.0, 0.0, 1.0, 0.5] for _ in range(filter_num1)]).astype(np.float32) \n",
        "\n",
        "grads_list_w1 = np.zeros((kernelsize,kernelsize,512,filter_num1))\n",
        "grads_list_b1 = np.zeros((filter_num1,))\n",
        "start = time.time()\n",
        "\n",
        "for batch_index in range(num_batches):\n",
        "    print('# of batch:',batch_index)\n",
        "    X, y = get_batch(train_images, train_label, batch_size) \n",
        "    W_x = intitial_W_x(X)\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred,opinion_conv = model_maxtrust([X, W_x, W_w1, W_b1])\n",
        "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)\n",
        "\n",
        "    grads = tape.gradient(loss, model_maxtrust.variables)\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(grads, model_maxtrust.variables))\n",
        "    # sparse_categorical_accuracy.reset_states()\n",
        "    sparse_categorical_accuracy.update_state(y_true=y, y_pred=y_pred)\n",
        "    print(\"train accuracy:\",sparse_categorical_accuracy.result().numpy())\n",
        "#     print('Model update end:',(time.time()-start))\n",
        "      \n",
        "# update W_w, W_b\n",
        "    grads_list_w1 = grads_list_w1 + tf.where(abs(grads[0]) < np.average(abs(grads[0])), 1, 0)  #  shape=(5, 5, 3, 8)\n",
        "    grads_list_b1 = grads_list_b1 + tf.where(abs(grads[1]) < np.average(abs(grads[1])), 1, 0)  #  shape=(8,\n",
        "    W_w1, W_b1 = get_update_matrix(grads_list_w1, grads_list_b1, batch_index+1)                               \n",
        "\n",
        "    y_N_update, y_N_op = evidence_collect(y, y_pred)  \n",
        "    y_N_opinion.append(y_N_op)\n",
        "    y_update_wb.append(y_N_update)\n",
        "   \n",
        "    print('One batch end:',(time.time()-start))"
      ],
      "metadata": {
        "id": "VEy3QD4heH8D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "fa94d0e3-76dc-4ead-db9e-beb079d16db3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2881\u001b[0m                 \u001b[0;31m#rprint('Running code', repr(code_obj)) # dbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2882\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2883\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-6956ad0f3a46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m W_w1 = np.array([[[[[0.0, 0.0, 1.0, 0.5] for _ in range(filter_num1)] for _ in range(512)] \n\u001b[0;32m----> 5\u001b[0;31m                   for _ in range(kernelsize)] for _ in range(kernelsize)]).astype(np.float32)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-6956ad0f3a46>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m W_w1 = np.array([[[[[0.0, 0.0, 1.0, 0.5] for _ in range(filter_num1)] for _ in range(512)] \n\u001b[0;32m----> 5\u001b[0;31m                   for _ in range(kernelsize)] for _ in range(kernelsize)]).astype(np.float32)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-6956ad0f3a46>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m W_w1 = np.array([[[[[0.0, 0.0, 1.0, 0.5] for _ in range(filter_num1)] for _ in range(512)] \n\u001b[0;32m----> 5\u001b[0;31m                   for _ in range(kernelsize)] for _ in range(kernelsize)]).astype(np.float32)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-6956ad0f3a46>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m W_w1 = np.array([[[[[0.0, 0.0, 1.0, 0.5] for _ in range(filter_num1)] for _ in range(512)] \n\u001b[0m\u001b[1;32m      5\u001b[0m                   for _ in range(kernelsize)] for _ in range(kernelsize)]).astype(np.float32)\n",
            "\u001b[0;32m<ipython-input-27-6956ad0f3a46>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m W_w1 = np.array([[[[[0.0, 0.0, 1.0, 0.5] for _ in range(filter_num1)] for _ in range(512)] \n\u001b[0m\u001b[1;32m      5\u001b[0m                   for _ in range(kernelsize)] for _ in range(kernelsize)]).astype(np.float32)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "def save_variable(v,filename):\n",
        "    f=open(filename,'wb')\n",
        "    pickle.dump(v,f)\n",
        "    f.close()\n",
        "    return filename\n",
        " \n",
        "def load_variavle(filename):\n",
        "    f=open(filename,'rb')\n",
        "    r=pickle.load(f)\n",
        "    f.close()\n",
        "    return r"
      ],
      "metadata": {
        "id": "cOZbi63AtM3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_maxtrust.save_weights('/content/drive/MyDrive/cnn trust/update/parameters/model_CIFAR10_transfer')\n",
        "# save_variable(W_w1, '/content/drive/MyDrive/cnn trust/update/parameters/CIFAR10_weight_with_MAX_Trust_transfer')\n",
        "# save_variable(W_b1, '/content/drive/MyDrive/cnn trust/update/parameters/CIFAR10_bias_with_MAX_Trust_transfer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EpVygD0WtRwI",
        "outputId": "be2819f2-b9b1-4977-9c6c-5a6cda3e16cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/cnn trust/update/parameters/CIFAR10_bias_with_MAX_Trust_transfer'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_maxtrust.load_weights('/content/drive/MyDrive/cnn trust/update/parameters/model_CIFAR10_transfer')\n",
        "W_w1 = load_variavle('/content/drive/MyDrive/cnn trust/update/parameters/CIFAR10_weight_with_MAX_Trust_transfer')\n",
        "W_b1 = load_variavle('/content/drive/MyDrive/cnn trust/update/parameters/CIFAR10_bias_with_MAX_Trust_transfer')"
      ],
      "metadata": {
        "id": "2OMhjiMlzH9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = test_feature[:500]\n",
        "test_data_label = test_label[:500]"
      ],
      "metadata": {
        "id": "kXMTcIVL0_MZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test data\n",
        "test_opinion = intitial_W_x(test_dataset)\n",
        "y_pred_test,opinion_test_last = model_maxtrust([test_dataset, test_opinion, W_w1, W_b1])\n",
        "sparse_categorical_accuracy.reset_states()\n",
        "sparse_categorical_accuracy.update_state(y_true=test_data_label, y_pred=y_pred_test)\n",
        "print(\"test accuracy:\",sparse_categorical_accuracy.result().numpy())"
      ],
      "metadata": {
        "id": "h-6VJEpn0Za2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a8f0861-7d45-4336-a909-61a8d1064846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import util\n",
        "class CIFARLoader():\n",
        "    \"\"\"\n",
        "    Dataset loader class\n",
        "    \n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        (self.train_data, self.train_label), (self.test_data, self.test_label) = tf.keras.datasets.cifar10.load_data()\n",
        "       \n",
        "        self.train_data = self.train_data.astype(np.float32)/ 255.0     # [50000, 32, 32, 3]\n",
        "        self.test_data = self.test_data.astype(np.float32) / 255.0      # [10000, 32, 32, 3]\n",
        "        self.train_label = self.train_label.astype(np.int32)    # [50000]\n",
        "        self.test_label = self.test_label.astype(np.int32)      # [10000]\n",
        "        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]\n",
        "\n",
        "    def get_batch(self, batch_size):\n",
        "        # 从数据集中随机取出batch_size个元素并返回\n",
        "        index = np.random.randint(0, self.num_train_data, batch_size)\n",
        "        return self.train_data[index, :], self.train_label[index]\n",
        "    def get_batch_damage_label(self, batch_size, percentage):\n",
        "        index = np.random.randint(0, self.num_train_data, batch_size)\n",
        "        batch_label = np.copy(self.train_label[index])\n",
        "        batch_label[:int(batch_size*percentage)] = 0\n",
        "        return self.train_data[index, :], batch_label\n",
        "    \n",
        "    def get_local_noise(self, noise_num=400, batch_size=5000):\n",
        "        \"\"\"\n",
        "        Generate noise_num # of gassaion noise knowing location \n",
        "        \n",
        "        \"\"\"\n",
        "\n",
        "        process_image = np.copy(self.test_data[:batch_size])\n",
        "        W_x = intitial_W_x(process_image)\n",
        "        uncer_mass = np.zeros(W_x[:,0,0,:,0].shape) + 0.01\n",
        "        base_rate = np.zeros(W_x[:,0,0,:,0].shape) + 0.5\n",
        "        image_size = process_image.shape[1]\n",
        "        index_noise = np.random.randint(0, image_size*image_size, noise_num)\n",
        "        \n",
        "        for i in index_noise:\n",
        "            noise_value = np.random.randn(batch_size,3) * 0.4\n",
        "            feature_value = process_image[:,int(i/image_size),int(i%image_size),:]\n",
        "            process_image[:,int(i/image_size),int(i%image_size),:] = feature_value + noise_value\n",
        "            belief_mass = W_x[:,int(i/image_size),int(i%image_size),:,0] \n",
        "            disbelief_mass = 1 - belief_mass - uncer_mass\n",
        "            W_x[:,int(i/image_size),int(i%image_size),:] = np.moveaxis(np.array([belief_mass,disbelief_mass,uncer_mass,base_rate]), 0, -1)\n",
        "            \n",
        "        return tf.clip_by_value(process_image, 0, 1), self.test_label[:batch_size], W_x, index_noise\n",
        "    \n",
        "    def get_noise(self, noise_mode):\n",
        "        process_image = np.copy(self.test_data[:400])\n",
        "        noise_gs_img = util.random_noise(process_image,mode=noise_mode, var=0.01)\n",
        "        return noise_gs_img, self.test_label[:400]\n",
        "\n",
        "    def get_test(self, size):\n",
        "\n",
        "        return self.test_data[:size], self.test_label[:size]\n",
        "    \n",
        "data_loader = CIFARLoader()"
      ],
      "metadata": {
        "cellView": "code",
        "id": "poqa5Gdi_svo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_noise, y_test_label = data_loader.get_noise('gaussian')\n",
        "test_feature_noise = model2.predict(X_test_noise)"
      ],
      "metadata": {
        "id": "78S7zoT48sgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_noise.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HipvsFepDye2",
        "outputId": "c2bae4eb-3453-42db-e928-c45578ccd3b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise_opinion = intitial_W_x(test_feature_noise)\n",
        "y_pred_test_noise,opinion_noise = model_maxtrust([test_feature_noise, noise_opinion, W_w1, W_b1])\n",
        "sparse_categorical_accuracy.reset_states()\n",
        "sparse_categorical_accuracy.update_state(y_true=y_test_label, y_pred=y_pred_test_noise)\n",
        "print(\"test accuracy:\",sparse_categorical_accuracy.result().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvxpvIjpzbI9",
        "outputId": "d37b48b5-6b4e-459d-f0f9-365b5873a8de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy: 0.095\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test localvar\n",
        "X_test_local_noise, y_test_local_noise, case1_opinion, noise_index = data_loader.get_local_noise()\n",
        "case2_opinion = intitial_W_x_location(X_test_local_noise, noise_index)\n",
        "case3_opinion = intitial_W_x(X_test_local_noise)\n",
        "y_pred_test_local_noise,_,_,opinion_noise = model_maxtrust([X_test_local_noise, case3_opinion, W_w1, W_b1, W_w2, W_b2])\n",
        "sparse_categorical_accuracy.reset_states()\n",
        "sparse_categorical_accuracy.update_state(y_true=y_test_local_noise, y_pred=y_pred_test_local_noise)\n",
        "print(\"test accuracy:\",sparse_categorical_accuracy.result().numpy())"
      ],
      "metadata": {
        "id": "G9JvPI1I-yd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_NN_trust(opinion_last_layer, true_label, pre_label, y_update_wb):\n",
        "    # compute dense opinion\n",
        "    opinion_dense = np.average(np.array(opinion_last_layer), axis=0)\n",
        "    opinion_dense = np.reshape(opinion_dense, (int(opinion_dense.shape[0]*opinion_dense.shape[1]*opinion_dense.shape[2]),4))\n",
        "    y_true_op = [1.0, 0.0, 0.0, 0.5]\n",
        "    W_y_update = evidence_collect_test(true_label, pre_label)\n",
        "    \n",
        "    # compute Backward opinion of neuron W_N_Y  \n",
        "    W_N_Y=[]\n",
        "    for j in W_y_update:\n",
        "        W_N_Y.append(multi(j,y_true_op)) # change when add flaw in label\n",
        "        \n",
        "    W_w_dense = y_update_wb[-1]\n",
        "    W_b_dense = y_update_wb[-1]\n",
        "\n",
        "    W_xw=[]\n",
        "    W_xw.append(W_b_dense)\n",
        "    for j in range(opinion_dense.shape[0]):\n",
        "        W_xw.append(multi(W_w_dense,opinion_dense[j])) # (513, 4)\n",
        "    dense_out = fusion(np.array(W_xw))\n",
        "    #     print('Underflow or not: ',np.isnan(np.min(np.array(dense1_out_list))))\n",
        "\n",
        "    # last layer\n",
        "    W_xw=[]\n",
        "    W_xw.append(W_b_dense)\n",
        "    for j in range(64):\n",
        "        W_xw.append(multi(W_w_dense,dense_out))\n",
        "    W_NN = fusion(np.array(W_xw))\n",
        "    \n",
        "    # compute last layer output opinion and trust\n",
        "    W_XY_one = []\n",
        "    for j in range(10):\n",
        "        W_XY_one.append(fusion_2(W_NN,W_N_Y[j]))\n",
        "    W_NN = fusion(np.array(W_XY_one))\n",
        "    W_trust = W_NN[0]+W_NN[2]*W_NN[3]\n",
        "    \n",
        "    return W_trust, W_NN"
      ],
      "metadata": {
        "id": "JUE6VRH8-1E2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TQ_FZ9z--39q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akAz_-O9PIsZ"
      },
      "source": [
        "from tensorflow.keras import Sequential, datasets,models,layers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D, DepthwiseConv2D, BatchNormalization\n",
        "from tensorflow.keras.models import load_model\n",
        "tf.random.set_seed(1)\n",
        "hidden_num = 128\n",
        "num_classes=10\n",
        "\n",
        "model_layers = [\n",
        "    Conv2D(32, (3, 3), activation='relu', strides=(1,1), padding='same', input_shape=(32, 32, 3)),\n",
        "    BatchNormalization(),\n",
        "    DepthwiseConv2D(kernel_size=(3,3), strides=(1, 1), padding='same', activation=keras.activations.relu, depth_multiplier=3),\n",
        "#     MaxPooling2D(2, 2),\n",
        "    Dropout(rate =0.1),\n",
        "    \n",
        "    \n",
        "    Conv2D(64, (3, 3), activation='relu', strides=(2, 2), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    DepthwiseConv2D(kernel_size=(3,3), strides=(1, 1), padding='same', activation=keras.activations.relu),\n",
        "#     MaxPooling2D(2, 2),\n",
        "    Dropout(rate = 0.1),\n",
        "    \n",
        "    Conv2D(128, (3, 3), activation='relu', strides=(1, 1), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    DepthwiseConv2D(kernel_size=(3,3), strides=(1, 1), padding='same', activation=keras.activations.relu),\n",
        "#     MaxPooling2D(2, 2),\n",
        "    Dropout(rate = 0.4),\n",
        "    \n",
        "    Conv2D(128, (3, 3), activation='relu', strides=(1, 1), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    DepthwiseConv2D(kernel_size=(1,1), strides=(1, 1), padding='same', activation=keras.activations.relu),\n",
        "    \n",
        "    \n",
        "    Conv2D(256, (3, 3), activation='relu', strides=(2, 2), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    DepthwiseConv2D(kernel_size=(3,3), strides=(1, 1), padding='same', activation=keras.activations.relu),\n",
        "    \n",
        "    \n",
        "    \n",
        "    Conv2D(512, (1, 1), activation='relu', strides=(2, 2), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    DepthwiseConv2D(kernel_size=(1,1), strides=(1, 1), padding='same', activation=keras.activations.relu),\n",
        "    Dropout(rate =0.3),\n",
        "\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "] \n",
        "model_ini = Sequential(model_layers)\n",
        "\n",
        "print(model_ini.summary())\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/cnn trust/update/parameters/model_CIFAR10_maxpool.h5', verbose=1, monitor='val_accuracy',save_best_only=True, mode='max')  \n",
        "model_ini.compile(optimizer='adam',\n",
        "                 loss=tf.keras.losses.sparse_categorical_crossentropy, \n",
        "                 metrics=['accuracy'],run_eagerly=True)\n",
        "\n",
        "history = model_ini.fit(train_images, train_label, batch_size=128, epochs=30, verbose=1, validation_data = (test_images, test_label), callbacks = [checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import sklearn\n",
        "from sklearn.metrics import auc, plot_precision_recall_curve\n",
        "\n",
        "model_maxpool = tf.keras.models.load_model('/content/drive/MyDrive/cnn trust/update/parameters/model_CIFAR10_maxpool.h5')\n",
        "model_maxpool.evaluate(test_images, test_label)\n",
        "\n",
        "y_pred = model_maxpool.predict(test_images)\n",
        "m = tf.keras.metrics.AUC(num_thresholds=200)\n",
        "m.update_state(tf.one_hot(test_label[:,0],depth=10), y_pred)\n",
        "auroc = m.result().numpy()\n",
        "\n",
        "y_pred = tf.math.argmax(y_pred,axis=1)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_label, y_pred,average='weighted')\n",
        "\n",
        "precision, recall, f1, auroc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJOGTwSD-ad8",
        "outputId": "fc5f135c-cc7e-4f06-afb8-2e29d837c8e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 4ms/step - loss: 0.6178 - accuracy: 0.8269\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8328486137695199, 0.8269, 0.8270987799956391, 0.9749063)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}