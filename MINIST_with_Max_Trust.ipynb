{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "YZdxOxa97fZO"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import util\n",
    "from math import exp, log\n",
    "from tensorflow.python.keras.engine.base_layer import Layer\n",
    "from matplotlib import rc\n",
    "rc('mathtext', default='regular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "r0dm5c_T7fZX"
   },
   "outputs": [],
   "source": [
    "class MNISTLoader():\n",
    "    def __init__(self):\n",
    "        mnist = tf.keras.datasets.mnist\n",
    "        (self.train_data, self.train_label), (self.test_data, self.test_label) = mnist.load_data()\n",
    "\n",
    "        self.train_data = np.expand_dims(self.train_data.astype(np.float32) / 255.0, axis=-1)      # [60000, 28, 28, 1]\n",
    "        self.test_data = np.expand_dims(self.test_data.astype(np.float32) / 255.0, axis=-1)        # [10000, 28, 28, 1]\n",
    "        self.train_label = self.train_label.astype(np.int32)    # [60000]\n",
    "        self.test_label = self.test_label.astype(np.int32)      # [10000]\n",
    "        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]\n",
    "\n",
    "    def get_batch(self, batch_size):\n",
    "\n",
    "        index = np.random.randint(0, self.num_train_data, batch_size)\n",
    "        return self.train_data[index, :], self.train_label[index]\n",
    "    \n",
    "    def get_batch_test(self):\n",
    "    \n",
    "        return self.test_data, self.test_label\n",
    "    \n",
    "    def get_local_noise(self, noise_num=400, batch_size=10000):\n",
    "        \"\"\"\n",
    "        Generate noise_num # of gassaion noise knowing location \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        process_image = np.copy(self.test_data[:batch_size])\n",
    "        W_x = intitial_W_x(process_image)\n",
    "        uncer_mass = np.zeros(W_x[:,0,0,:,0].shape) + 0.01\n",
    "        base_rate = np.zeros(W_x[:,0,0,:,0].shape) + 0.5\n",
    "        image_size = process_image.shape[1]\n",
    "        index_noise = np.random.randint(0, image_size*image_size, noise_num)\n",
    "        \n",
    "        for i in index_noise:\n",
    "            noise_value = np.random.randn(batch_size,1) * 0.4\n",
    "            feature_value = process_image[:,int(i/image_size),int(i%image_size),:]\n",
    "            process_image[:,int(i/image_size),int(i%image_size),:] = feature_value + noise_value\n",
    "            belief_mass = W_x[:,int(i/image_size),int(i%image_size),:,0] * (1-noise_value)\n",
    "            disbelief_mass = 1 - belief_mass - uncer_mass\n",
    "            W_x[:,int(i/image_size),int(i%image_size),:] = np.moveaxis(np.array([belief_mass,disbelief_mass,uncer_mass,base_rate]), 0, -1)\n",
    "            \n",
    "        return tf.clip_by_value(process_image, 0, 1), self.test_label[:batch_size], W_x, index_noise\n",
    "\n",
    "    \n",
    "    \n",
    "    def get_noise(self, noise_mode):\n",
    "        process_image = np.copy(self.test_data)\n",
    "        noise_gs_img = util.random_noise(process_image,mode=noise_mode,var=0.2)\n",
    "        return noise_gs_img, self.test_label\n",
    "    \n",
    "data_loader = MNISTLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "kFxBUMwrU1sC"
   },
   "outputs": [],
   "source": [
    "def intitial_opinion_trust(X):\n",
    "    \"\"\"\n",
    "    X - 50,32,32,3\n",
    "    return W_x - 50,32,32,3,4\n",
    "    \n",
    "    \"\"\"\n",
    "    W_dis = np.zeros(X.shape).astype(np.float32)\n",
    "    W_base = W_dis + 0.5\n",
    "    W_x = np.array([X, W_dis, 1 - X, W_base]).astype(np.float32)\n",
    "    x_trust = (W_x[0] + W_x[2] * 0.5)\n",
    "    W_x = np.moveaxis(W_x, 0, -1)\n",
    "    \n",
    "    return W_x, x_trust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intitial_W_x_location(X, index):\n",
    "    \"\"\"\n",
    "    X - 5000,28,28,1\n",
    "    return W_x - 400,\n",
    "    \n",
    "    \"\"\"\n",
    "    W_x = intitial_W_x(X)\n",
    "    uncer_mass = np.zeros(W_x[:,0,0,:,0].shape) + 0.01\n",
    "    base_rate = np.zeros(W_x[:,0,0,:,0].shape) + 0.5\n",
    "    image_size = X.shape[1]\n",
    "    for i in index:\n",
    "        belief_mass = W_x[:,int(i/image_size),int(i%image_size),:,0]\n",
    "        disbelief_mass = 1 - belief_mass - uncer_mass\n",
    "        W_x[:,int(i/image_size),int(i%image_size),:] = np.moveaxis(np.array([belief_mass,disbelief_mass,uncer_mass,base_rate]), 0, -1)\n",
    "\n",
    "    return W_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "bXJNv0AWxVOC"
   },
   "outputs": [],
   "source": [
    "def padding(opinion, kernel_size):\n",
    "    \"\"\"\n",
    "    opinion - (batch_size 500, image_size 32， image_size 32，channel 3, 4) \n",
    "    W_w - (kernel_size, kernel_size, 3, filter_num, 4)\n",
    "    p - int(( n_W_prev - f + 2 * pad )/ stride) + 1\n",
    "    \n",
    "    \"\"\"\n",
    "    image_size = opinion.shape[1]\n",
    "    p = int((kernel_size - 1)/2)\n",
    "    padding_size = int(image_size + 2 * p)\n",
    "    opinion_pad = np.zeros((int(opinion.shape[0]),padding_size,padding_size,int(opinion.shape[-2]),int(opinion.shape[-1])))\n",
    "    opinion_pad[:,:,:,:] = np.array([0.0, 0.99, 0.01, 0.5])\n",
    "    opinion_pad[:,p:p+image_size,p:p+image_size,:,:] = opinion\n",
    "    return opinion_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "yvzahj3w7fZZ"
   },
   "outputs": [],
   "source": [
    "def multi(W_x, W_y): # \n",
    "    W_x = W_x.astype(np.float64) \n",
    "    W_y = W_y.astype(np.float64) \n",
    "#     print(np.isnan(np.min(W_x[0]*W_y[0])))    \n",
    "    W_b = W_x[0]*W_y[0]+((1-W_x[3])*W_y[3]*W_x[0]*W_y[2]+W_x[3]*(1-W_y[3])*W_y[0]*W_x[2])/(1-W_x[3]*W_y[3])\n",
    "#     print(np.isnan(np.min(W_b)))\n",
    "    W_d = W_x[1]+W_y[1]-W_x[1]*W_y[1]\n",
    "    W_u = W_x[2]*W_y[2]+((1-W_y[3])*W_x[0]*W_y[2]+(1-W_x[3])*W_y[0]*W_x[2])/(1-W_x[3]*W_y[3])\n",
    "    W_a = W_x[3]*W_y[3]\n",
    "    return W_b,W_d,W_u,W_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "HGsdrX0k7fZZ"
   },
   "outputs": [],
   "source": [
    "def conv_single_step_trust(W_x, W_w, W_b): \n",
    "    \"\"\"\n",
    "    W_x - (50,5,5,3,4)\n",
    "    W_w - (5,5,3,32,4)\n",
    "    W_b - (32,4)\n",
    "    W_wx - (4, 32, 3, 5, 5)\n",
    "    fusion_result - (32,)\n",
    "    \n",
    "    \"\"\"    \n",
    "    W_x = W_x.astype(np.float64)   \n",
    "    W_w = W_w.numpy().astype(np.float64) \n",
    "    W_b = W_b.numpy().astype(np.float64) \n",
    "    \n",
    "    filter_number = W_b.shape[0]\n",
    "    batch_size = W_x.shape[0]\n",
    "    fusion_result = []\n",
    "    W_x_expand = np.tile(np.expand_dims(W_x, axis=(4)), [1,1,1,1,filter_number,1])\n",
    "    W_w_expand = np.tile(np.expand_dims(W_w, axis=(0)), [batch_size,1,1,1,1,1])\n",
    "    W_b_expand = np.tile(np.expand_dims(W_b, axis=(0)), [batch_size,1,1])\n",
    "#     print(W_x_expand,W_w_expand)\n",
    "#     print('W_x_expand',np.isnan(np.min(W_x_expand)))\n",
    "#     print('W_w_expand',np.isnan(np.min(W_w_expand)))\n",
    "    W_wx = multi(np.transpose(W_x_expand),np.transpose(W_w_expand)) # (4, 32, 3, 5, 5, 50)\n",
    "#     print(np.asarray(W_wx)[:])\n",
    "#     print(np.isnan(np.min(W_wx)))\n",
    "    fusion_result = avg_fusion(np.asarray(W_wx), np.transpose(W_b_expand))\n",
    "#     print(np.isnan(np.min(fusion_result[0])))\n",
    "    return np.transpose(fusion_result[0]),np.transpose(fusion_result[1])\n",
    "\n",
    "def avg_fusion(W_wx, W_b):\n",
    "    \"\"\"\n",
    "    W_wx - (4, 32, 3, 5, 5, 50)\n",
    "    W_b -  (4, 32, 50)\n",
    "    fusion_result - (32, 32, 32)\n",
    "    \n",
    "    return opinion - 4,32,50\n",
    "           trust - 32,50\n",
    "    \"\"\"\n",
    "    \n",
    "    W_wx = np.reshape(W_wx, (W_wx.shape[0],W_wx.shape[1], \n",
    "                             W_wx.shape[2]*W_wx.shape[3]*W_wx.shape[4], W_wx.shape[5])).astype(np.float64) # (4, 32, 75, 50)\n",
    "    W_b = W_b.astype(np.float64)\n",
    "    \n",
    "    n_filter = W_b.shape[1]\n",
    "    batch_size = W_wx.shape[-1]\n",
    "    num_para = W_wx.shape[2]\n",
    "#     print(num_para)\n",
    "    b_wx, u_wx, a_wx = W_wx[0], W_wx[2], W_wx[3]\n",
    "    b_b, u_b, a_b = W_b[0], W_b[2], W_b[3]\n",
    "        \n",
    "    \n",
    "    u_combine = np.concatenate((u_wx, np.reshape(u_b,(u_b.shape[0], 1, batch_size))), axis=1) # (32, 76, 50)\n",
    "    b_combine = np.concatenate((b_wx, np.reshape(b_b,(b_b.shape[0], 1, batch_size))), axis=1) # (32, 76, 50)\n",
    "    u_combine_recip = (np.zeros(u_combine.shape)+1)/u_combine\n",
    "    \n",
    "    numerator = np.sum(b_combine * u_combine_recip, axis = 1) # (32, 50)\n",
    "    denominator = np.sum(u_combine_recip, axis = (1))\n",
    "    \n",
    "    b_fusion = numerator / denominator\n",
    "    u_fusion = (num_para+1) / denominator\n",
    "    a_fusion = (np.sum(a_wx, axis=(1)) + a_b) / (num_para+1)\n",
    "    \n",
    "    return np.array([b_fusion, 1-b_fusion-u_fusion, u_fusion, a_fusion]).astype(np.float32), (b_fusion + u_fusion * a_fusion).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "7lg8hAmI7fZa"
   },
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W_w, W_b):\n",
    "    \"\"\"\n",
    "        A_prev - (batch_size 500, image_size 32， image_size 32，channel 3, 4) \n",
    "        W_w - (kernel_size, kernel_size, 3, filter_num, 4)\n",
    "        W_b - (filter_num, 4)\n",
    "        return Z - (28, 28, filter_num, 4)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    #获取来自上一层数据的基本信息\n",
    "#     print(A_prev.shape,W_w.shape)\n",
    "    (batch_size, n_H_prev, n_W_prev, _, _) = A_prev.shape\n",
    "    \n",
    "    #获取权重矩阵的基本信息\n",
    "    ( f , f , _, n_C, _) = W_w.shape\n",
    "\n",
    "\n",
    "    #获取超参数hparameters的值\n",
    "    stride = 1\n",
    "    pad = 1\n",
    "    \n",
    "    # padding opinion\n",
    "    A_prev_pad = padding(A_prev,f)\n",
    "    \n",
    "    #计算卷积后的图像的宽度高度，参考上面的公式，使用int()来进行板除\n",
    "    n_H = int(( n_H_prev - f + 2 * pad )/ stride) + 1\n",
    "    n_W = int(( n_W_prev - f + 2 * pad )/ stride) + 1\n",
    " \n",
    "    \n",
    "    #使用0来初始化卷积输出Z\n",
    "    Z = np.zeros((batch_size, n_H, n_W, n_C, 4)) \n",
    "    Z_trust = np.zeros((batch_size, n_H, n_W, n_C))\n",
    "\n",
    "    for h in range(n_H):                       \n",
    "        for w in range(n_W):                              \n",
    "            vert_start = h * stride        \n",
    "            vert_end = vert_start + f       \n",
    "            horiz_start = w * stride        \n",
    "            horiz_end = horiz_start + f     \n",
    "            a_slice_prev = A_prev_pad[:,vert_start:vert_end,horiz_start:horiz_end,:,:]   # 500, 3, 3, 3, 4\n",
    "#             print(a_slice_prev)\n",
    "#             print('a_slice_prev :', np.isnan(np.min(a_slice_prev)))\n",
    "            opinion, trust = conv_single_step_trust(a_slice_prev,W_w,W_b)   \n",
    "#             print(opinion.shape)\n",
    "            Z[:,h,w,:,:] = opinion\n",
    "            Z_trust[:,h,w,:] = trust\n",
    "#     print(Z.shape,Z_trust.shape)\n",
    "    return Z, Z_trust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "HJbAPUO37fZY"
   },
   "outputs": [],
   "source": [
    "class MyLayerMaxTrust(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    max-trust fuction layer\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MyLayerMaxTrust, self).__init__()\n",
    "\n",
    "\n",
    "    def call(self, x, opinion, trust):\n",
    "        \"\"\"\n",
    "        x - (50, 28, 28, 32)\n",
    "        opinion - (50, 28, 28, 32, 4)\n",
    "        trust - (50, 28, 28, 32)\n",
    "        \n",
    "        x, pooling_opinion1 = self.maxtrust(x, opinion1, trust1)\n",
    "\n",
    "        opinion_out - (50, 14, 14, 32, 4)\n",
    "        return - (50, 14, 14, 32, 4)\n",
    "\n",
    "        \"\"\"\n",
    "    #         print(inputs.shape,inputB.shape)\n",
    "        trust_mul = np.zeros(x.shape)\n",
    "        image_size = x.shape[1]\n",
    "        opinion_out = np.zeros((opinion.shape[0],int(opinion.shape[1]/2), int(opinion.shape[2]/2),opinion.shape[3], 4)).astype(np.float32)\n",
    "#         print(opinion_out.shape)\n",
    "        for i in range(trust.shape[0]):\n",
    "            for k in range(trust.shape[-1]):\n",
    "                input_max = trust[i,:,:,k].reshape((1,trust.shape[1],trust.shape[2],1))\n",
    "                _, argmax = tf.nn.max_pool_with_argmax(input = input_max, ksize = [1, 2, 2, 1],\n",
    "                                                    strides = [1, 2, 2, 1], padding = 'VALID')\n",
    "                argmax_1d = argmax.numpy().flatten()\n",
    "#                 print(len(argmax_1d))\n",
    "            \n",
    "                for j in range(len(argmax_1d)):\n",
    "                    trust_mul[i,int(argmax_1d[j]/image_size),int(argmax_1d[j]%image_size),k] = 1\n",
    "                    opinion_out[i,int(j/int(image_size/2)), int(j%int(image_size/2)),k,:] = opinion[i,int(argmax_1d[j]/image_size),int(argmax_1d[j]%image_size),k,:] \n",
    "\n",
    "        x = x * trust_mul\n",
    "\n",
    "        return x, opinion_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "l0xqqyWB7fZZ"
   },
   "outputs": [],
   "source": [
    "class MyLayerCONV(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    max-trust fuction layer\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MyLayerCONV, self).__init__()\n",
    "\n",
    "\n",
    "    def call(self, input1, input2, input3):\n",
    "        \n",
    "        Z, Z_trust = conv_forward(input1, input2, input3)\n",
    "           \n",
    "        return Z.astype(np.float32), Z_trust.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "dLQTm3SOxVOF"
   },
   "outputs": [],
   "source": [
    "class MyLayerMaxPool(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    original max-pooling with trust\n",
    "     \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MyLayerMaxPool, self).__init__()\n",
    "\n",
    "\n",
    "    def call(self, x, opinion):\n",
    "        \"\"\"\n",
    "        x-(50,14,14,8)\n",
    "        \n",
    "        \"\"\"\n",
    "        image_size = x.shape[1]\n",
    "        opinion_out = np.zeros((opinion.shape[0],int(opinion.shape[1]/2), \n",
    "                                int(opinion.shape[2]/2),opinion.shape[3], 4)).astype(np.float32)\n",
    "\n",
    "        for i in range(x.shape[0]):\n",
    "            for k in range(x.shape[-1]):\n",
    "                input_max = x[i,:,:,k].numpy().reshape((1,x.shape[1],x.shape[2],1))\n",
    "                _, argmax = tf.nn.max_pool_with_argmax(input = input_max, ksize = [1, 2, 2, 1],\n",
    "                                                    strides = [1, 2, 2, 1], padding = 'VALID')\n",
    "                argmax_1d = argmax.numpy().flatten()\n",
    "                for j in range(len(argmax_1d)):\n",
    "                    opinion_out[i,int(j/int(image_size/2)), int(j%int(image_size/2)),k,:] = opinion[i,int(argmax_1d[j]/image_size),\n",
    "                                                                                                    int(argmax_1d[j]%image_size),k,:] \n",
    "        return opinion_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayerComputeTrust(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    input- (50,14,14,8)\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MyLayerComputeTrust, self).__init__()\n",
    "\n",
    "\n",
    "    def call(self, input1):\n",
    "        \n",
    "        opinion, trust = intitial_opinion_trust(input1)\n",
    "           \n",
    "        return opinion, trust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "15za74YC7fZa"
   },
   "outputs": [],
   "source": [
    "def get_update_matrix(grads_w, grads_b, rs):\n",
    "    \"\"\"\n",
    "    grads_list_w1 = grads_list_w + tf.where(abs(tf.squeeze(grads[0]))<0.01, 1, 0)  #  shape=(5, 5, 3, 32)\n",
    "    grads_list_b1 = grads_list_b + tf.where(abs(tf.squeeze(grads[1]))<0.01, 1, 0)  #  shape=(32,)\n",
    "    grads_list_w2 = grads_list_w + tf.where(abs(tf.squeeze(grads[0]))<0.01, 1, 0)  #  shape=(5, 5, 32, 64)\n",
    "    grads_list_b2 = grads_list_b + tf.where(abs(tf.squeeze(grads[1]))<0.01, 1, 0)  #  shape=(64,)\n",
    "    grads_list_w3 = grads_list_w + tf.where(abs(tf.squeeze(grads[0]))<0.01, 1, 0)  #  shape=(5, 5, 64, 64)\n",
    "    grads_list_b3 = grads_list_b + tf.where(abs(tf.squeeze(grads[1]))<0.01, 1, 0)  #  shape=(64,)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    W_w = np.array([grads_w/(rs+2),(rs-grads_w)/(rs+2),np.full(grads_w.shape, 2/(rs+2)),\n",
    "                    np.full(grads_w.shape, 0.5)]).astype(np.float32)\n",
    "    W_b = np.array([grads_b/(rs+2), (rs-grads_b)/(rs+2), np.full(grads_b.shape, 2/(rs+2)), \n",
    "                    np.full(grads_b.shape, 0.5)]).astype(np.float32)\n",
    "    W_w = np.moveaxis(W_w, 0, -1)\n",
    "    \n",
    "    return W_w, W_b.swapaxes(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "yby1VsHD5SGv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filter_num1 = 4\n",
    "filter_num2 = 8\n",
    "filter_num3 = 8\n",
    "kernelsize = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convopinion1 = MyLayerCONV()\n",
    "        self.convopinion2 = MyLayerCONV()\n",
    "        self.convopinion3 = MyLayerCONV()\n",
    "        self.compute_trust = MyLayerComputeTrust()\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2D(\n",
    "            filters=filter_num1,             \n",
    "            kernel_size=[kernelsize, kernelsize],\n",
    "            padding='same',\n",
    "            activation=tf.nn.relu   \n",
    "        )\n",
    "        self.conv2 = tf.keras.layers.Conv2D(\n",
    "            filters=filter_num2,           \n",
    "            kernel_size=[kernelsize, kernelsize],    \n",
    "            padding='same',\n",
    "            activation=tf.nn.relu   \n",
    "        )\n",
    "        self.conv3 = tf.keras.layers.Conv2D(\n",
    "            filters=filter_num3,            \n",
    "            kernel_size=[kernelsize, kernelsize],     \n",
    "            padding='same',         \n",
    "            activation=tf.nn.relu   \n",
    "        )\n",
    "\n",
    "        self.maxtrust1 = MyLayerMaxTrust()\n",
    "        self.maxtrust2 = MyLayerMaxTrust()\n",
    "        self.maxfeature1 = MyLayerMaxPool()\n",
    "        self.maxfeature2 = MyLayerMaxPool()\n",
    "        \n",
    "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n",
    "       \n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(units=64, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=10, activation=tf.nn.softmax)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        x - 50,32,32,3\n",
    "        W_x - 50,32,32,3,4\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        X, W_x, W_w1, W_b1, W_w2, W_b2 = inputs\n",
    " \n",
    "        opinion1, trust1 = self.convopinion1(W_x, W_w1, W_b1)\n",
    "        x = self.conv1(X)   \n",
    "#         print(np.isnan(np.min(opinion1)))\n",
    "#         print('Underflow or not: ',np.isnan(np.min(trust1)))\n",
    "#         print(opinion1.shape,trust1.shape)\n",
    "        x, pooling_opinion1 = self.maxtrust1(x, opinion1, trust1)\n",
    "#         pooling_opinion1 = self.maxfeature1(x, opinion1)\n",
    "        x = self.pool1(x) \n",
    "#         print('First 2 layers end:',(time.time()-start))\n",
    "#         print(np.isnan(np.min(x)))\n",
    "#         print(np.isnan(np.min(pooling_opinion1)))\n",
    "        opinion2, _ = self.convopinion2(pooling_opinion1, W_w2, W_b2)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        pooling_opinion2 = self.maxfeature2(x, opinion2)\n",
    "        x = self.pool2(x)\n",
    "#         print(np.isnan(np.min(opinion2)))\n",
    "#         print(np.isnan(np.min(x)))\n",
    "#         print('Second 2 layers end:',(time.time()-start))\n",
    "        \n",
    "        x = self.flatten(x) \n",
    "        x = self.dense1(x)    \n",
    "        output = self.dense2(x)                    \n",
    "        return output,opinion1,opinion2,pooling_opinion2\n",
    "    \n",
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "ZMt5J6p-7fZb"
   },
   "outputs": [],
   "source": [
    "# initial opinion\n",
    "# W_x = np.array([[[[0.0, 0.0, 1.0, 0.5] for _ in range(3)] for _ in range(32)] for _ in range(32)]).astype(np.float32)\n",
    "\n",
    "w_initial1 = np.array([[[[[0.0, 0.0, 1.0, 0.5] for _ in range(filter_num1)] \n",
    "                         for _ in range(1)] for _ in range(kernelsize)] for _ in range(kernelsize)]).astype(np.float32)\n",
    "b_initial1 = np.array([[0.0, 0.0, 1.0, 0.5] for _ in range(filter_num1)]).astype(np.float32)\n",
    "\n",
    "w_initial2 = np.array([[[[[0.0, 0.0, 1.0, 0.5] for _ in range(filter_num2)] \n",
    "                         for _ in range(filter_num1)] for _ in range(kernelsize)] for _ in range(kernelsize)]).astype(np.float32)\n",
    "b_initial2 = np.array([[0.0, 0.0, 1.0, 0.5] for _ in range(filter_num2)]).astype(np.float32)\n",
    "\n",
    "# w_initial3 = np.array([[[[[0.0, 0.0, 1.0, 0.5] for _ in range(filter_num3)] \n",
    "#                          for _ in range(filter_num2)] for _ in range(kernelsize)] for _ in range(kernelsize)]).astype(np.float32)\n",
    "# b_initial3 = np.array([[0.0, 0.0, 1.0, 0.5] for _ in range(filter_num3)]).astype(np.float32)\n",
    "\n",
    "# w_initial4 = np.array([[[0.0, 0.0, 1.0, 0.5] for _ in range(64)] for _ in range(784)]).astype(np.float32)\n",
    "# b_initial4 = np.array([[0.0, 0.0, 1.0, 0.5] for _ in range(64)]).astype(np.float32)\n",
    "\n",
    "# w_initial5 = np.array([[[0.0, 0.0, 1.0, 0.5] for _ in range(10)] for _ in range(64)]).astype(np.float32)\n",
    "# b_initial5 = np.array([[0.0, 0.0, 1.0, 0.5] for _ in range(10)]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "lgpZvsdWxVOG"
   },
   "outputs": [],
   "source": [
    "def evidence_collect(y, y_pred):\n",
    "    r = 0\n",
    "    s = 0\n",
    "    r_list = [0]*10\n",
    "    s_list = [0]*10\n",
    "    \n",
    "    for j in range(len(y_pred)):\n",
    "        for i in range(len(y_pred[0])):\n",
    "            if i == y[j]:\n",
    "                if y_pred[j][i] > 0.8:\n",
    "                    r_list[i]+=1\n",
    "                    r+=1\n",
    "                else:\n",
    "                    s+=1\n",
    "                    s_list[i]+=1\n",
    "            else:\n",
    "                if y_pred[j][i] < 0.2:\n",
    "                    r_list[i]+=1\n",
    "                else:\n",
    "                    s_list[i]+=1\n",
    "                    \n",
    "    y_N_op = []\n",
    "    for i in range(len(r_list)):\n",
    "        y_N_op.append([r_list[i]/(r_list[i]+s_list[i]+2), \n",
    "                       s_list[i]/(r_list[i]+s_list[i]+2), 2/(r_list[i]+s_list[i]+2), 0.5])\n",
    "\n",
    "    \n",
    "    return [r/(r+s+2), s/(r+s+2), 2/(r+s+2), 0.5], y_N_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "2mYRIhMy7fZY"
   },
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "batch_size = 50\n",
    "threshold1 = 3.0\n",
    "threshold2 = 10.0\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "sparse_categorical_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "LsdJSsfTxVOH"
   },
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "train_loss = []\n",
    "opinion_convlist = []\n",
    "y_update_wb = []\n",
    "y_N_opinion = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1677183,
     "status": "ok",
     "timestamp": 1615854665861,
     "user": {
      "displayName": "Mingxi Cheng",
      "photoUrl": "",
      "userId": "11732313048760842335"
     },
     "user_tz": 420
    },
    "id": "_Cc0BUeq7fZb",
    "outputId": "79e7baeb-3245-47e1-e8cb-7f9f01ab3e02",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of batch: 0\n",
      "train accuracy: 0.12\n",
      "One batch end: 0.8329989910125732\n",
      "# of batch: 1\n",
      "train accuracy: 0.14\n",
      "One batch end: 1.5309984683990479\n",
      "# of batch: 2\n",
      "train accuracy: 0.18\n",
      "One batch end: 2.2260687351226807\n",
      "# of batch: 3\n",
      "train accuracy: 0.165\n",
      "One batch end: 2.9090683460235596\n",
      "# of batch: 4\n",
      "train accuracy: 0.16\n",
      "One batch end: 3.603067636489868\n",
      "# of batch: 5\n",
      "train accuracy: 0.16333333\n",
      "One batch end: 4.289067983627319\n",
      "# of batch: 6\n",
      "train accuracy: 0.18\n",
      "One batch end: 4.9773054122924805\n",
      "# of batch: 7\n",
      "train accuracy: 0.1825\n",
      "One batch end: 5.664304733276367\n",
      "# of batch: 8\n",
      "train accuracy: 0.18666667\n",
      "One batch end: 6.349303960800171\n",
      "# of batch: 9\n",
      "train accuracy: 0.182\n",
      "One batch end: 7.03230357170105\n",
      "# of batch: 10\n",
      "train accuracy: 0.19272727\n",
      "One batch end: 7.712303161621094\n",
      "# of batch: 11\n",
      "train accuracy: 0.2\n",
      "One batch end: 8.468382596969604\n",
      "# of batch: 12\n",
      "train accuracy: 0.20307693\n",
      "One batch end: 9.170385837554932\n",
      "# of batch: 13\n",
      "train accuracy: 0.20857143\n",
      "One batch end: 9.923385381698608\n",
      "# of batch: 14\n",
      "train accuracy: 0.22133334\n",
      "One batch end: 10.700400590896606\n",
      "# of batch: 15\n",
      "train accuracy: 0.2375\n",
      "One batch end: 11.405395269393921\n",
      "# of batch: 16\n",
      "train accuracy: 0.24470589\n",
      "One batch end: 12.11039924621582\n",
      "# of batch: 17\n",
      "train accuracy: 0.24666667\n",
      "One batch end: 12.853476762771606\n",
      "# of batch: 18\n",
      "train accuracy: 0.25368422\n",
      "One batch end: 13.548476219177246\n",
      "# of batch: 19\n",
      "train accuracy: 0.264\n",
      "One batch end: 14.230474948883057\n",
      "# of batch: 20\n",
      "train accuracy: 0.2752381\n",
      "One batch end: 14.9944748878479\n",
      "# of batch: 21\n",
      "train accuracy: 0.28454545\n",
      "One batch end: 15.678135633468628\n",
      "# of batch: 22\n",
      "train accuracy: 0.2895652\n",
      "One batch end: 16.413135290145874\n",
      "# of batch: 23\n",
      "train accuracy: 0.29166666\n",
      "One batch end: 17.19113039970398\n",
      "# of batch: 24\n",
      "train accuracy: 0.2976\n",
      "One batch end: 17.874133825302124\n",
      "# of batch: 25\n",
      "train accuracy: 0.31\n",
      "One batch end: 18.58521556854248\n",
      "# of batch: 26\n",
      "train accuracy: 0.31555554\n",
      "One batch end: 19.286273956298828\n",
      "# of batch: 27\n",
      "train accuracy: 0.32714286\n",
      "One batch end: 19.98327326774597\n",
      "# of batch: 28\n",
      "train accuracy: 0.33310345\n",
      "One batch end: 20.66527247428894\n",
      "# of batch: 29\n",
      "train accuracy: 0.346\n",
      "One batch end: 21.387272119522095\n",
      "# of batch: 30\n",
      "train accuracy: 0.35225806\n",
      "One batch end: 22.112356185913086\n",
      "# of batch: 31\n",
      "train accuracy: 0.359375\n",
      "One batch end: 22.89335584640503\n",
      "# of batch: 32\n",
      "train accuracy: 0.36666667\n",
      "One batch end: 23.573355436325073\n",
      "# of batch: 33\n",
      "train accuracy: 0.37411764\n",
      "One batch end: 24.25435471534729\n",
      "# of batch: 34\n",
      "train accuracy: 0.38\n",
      "One batch end: 24.935353994369507\n",
      "# of batch: 35\n",
      "train accuracy: 0.38333333\n",
      "One batch end: 25.617353439331055\n",
      "# of batch: 36\n",
      "train accuracy: 0.39081082\n",
      "One batch end: 26.29943561553955\n",
      "# of batch: 37\n",
      "train accuracy: 0.39789474\n",
      "One batch end: 26.98143482208252\n",
      "# of batch: 38\n",
      "train accuracy: 0.40717947\n",
      "One batch end: 27.6644344329834\n",
      "# of batch: 39\n",
      "train accuracy: 0.4135\n",
      "One batch end: 28.34843373298645\n",
      "# of batch: 40\n",
      "train accuracy: 0.41658536\n",
      "One batch end: 29.031429052352905\n",
      "# of batch: 41\n",
      "train accuracy: 0.42\n",
      "One batch end: 29.769432544708252\n",
      "# of batch: 42\n",
      "train accuracy: 0.42465118\n",
      "One batch end: 67.98266863822937\n",
      "# of batch: 43\n",
      "train accuracy: 0.42863637\n",
      "One batch end: 68.72566866874695\n",
      "# of batch: 44\n",
      "train accuracy: 0.43244445\n",
      "One batch end: 69.43566823005676\n",
      "# of batch: 45\n",
      "train accuracy: 0.43652174\n",
      "One batch end: 70.2736668586731\n",
      "# of batch: 46\n",
      "train accuracy: 0.44340426\n",
      "One batch end: 71.1746666431427\n",
      "# of batch: 47\n",
      "train accuracy: 0.4475\n",
      "One batch end: 71.88066625595093\n",
      "# of batch: 48\n",
      "train accuracy: 0.45306122\n",
      "One batch end: 72.59469032287598\n",
      "# of batch: 49\n",
      "train accuracy: 0.4572\n",
      "One batch end: 73.32570767402649\n",
      "# of batch: 50\n",
      "train accuracy: 0.46039215\n",
      "One batch end: 74.03870749473572\n",
      "# of batch: 51\n",
      "train accuracy: 0.46384615\n",
      "One batch end: 74.79770874977112\n",
      "# of batch: 52\n",
      "train accuracy: 0.46679246\n",
      "One batch end: 75.58870697021484\n",
      "# of batch: 53\n",
      "train accuracy: 0.47037038\n",
      "One batch end: 76.31475520133972\n",
      "# of batch: 54\n",
      "train accuracy: 0.47309092\n",
      "One batch end: 77.00470566749573\n",
      "# of batch: 55\n",
      "train accuracy: 0.47642857\n",
      "One batch end: 77.77870512008667\n",
      "# of batch: 56\n",
      "train accuracy: 0.47894737\n",
      "One batch end: 78.54769992828369\n",
      "# of batch: 57\n",
      "train accuracy: 0.48344827\n",
      "One batch end: 79.2497034072876\n",
      "# of batch: 58\n",
      "train accuracy: 0.4881356\n",
      "One batch end: 79.97170042991638\n",
      "# of batch: 59\n",
      "train accuracy: 0.494\n",
      "One batch end: 80.6727020740509\n",
      "# of batch: 60\n",
      "train accuracy: 0.49934426\n",
      "One batch end: 81.50270175933838\n",
      "# of batch: 61\n",
      "train accuracy: 0.5035484\n",
      "One batch end: 82.32069683074951\n",
      "# of batch: 62\n",
      "train accuracy: 0.508254\n",
      "One batch end: 83.1037015914917\n",
      "# of batch: 63\n",
      "train accuracy: 0.5103125\n",
      "One batch end: 83.84069991111755\n",
      "# of batch: 64\n",
      "train accuracy: 0.51415384\n",
      "One batch end: 84.55369925498962\n",
      "# of batch: 65\n",
      "train accuracy: 0.5163636\n",
      "One batch end: 85.2496988773346\n",
      "# of batch: 66\n",
      "train accuracy: 0.5197015\n",
      "One batch end: 85.93969821929932\n",
      "# of batch: 67\n",
      "train accuracy: 0.52411765\n",
      "One batch end: 86.65969753265381\n",
      "# of batch: 68\n",
      "train accuracy: 0.52724636\n",
      "One batch end: 87.34169721603394\n",
      "# of batch: 69\n",
      "train accuracy: 0.5297143\n",
      "One batch end: 88.02874636650085\n",
      "# of batch: 70\n",
      "train accuracy: 0.5332394\n",
      "One batch end: 88.73969602584839\n",
      "# of batch: 71\n",
      "train accuracy: 0.5375\n",
      "One batch end: 89.42169547080994\n",
      "# of batch: 72\n",
      "train accuracy: 0.54164386\n",
      "One batch end: 90.10269069671631\n",
      "# of batch: 73\n",
      "train accuracy: 0.5448649\n",
      "One batch end: 90.78569436073303\n",
      "# of batch: 74\n",
      "train accuracy: 0.5485333\n",
      "One batch end: 91.49869513511658\n",
      "# of batch: 75\n",
      "train accuracy: 0.55105263\n",
      "One batch end: 92.21069407463074\n",
      "# of batch: 76\n",
      "train accuracy: 0.55454546\n",
      "One batch end: 92.92169284820557\n",
      "# of batch: 77\n",
      "train accuracy: 0.55846155\n",
      "One batch end: 93.63469243049622\n",
      "# of batch: 78\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-78e16846d1f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mW_x\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintitial_opinion_trust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopinion_conv1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopinion_conv2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopinion_conv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_w1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_b1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_w2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_b2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_categorical_crossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\TF2.4.1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1012\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-79-a9e9c56cb6d9>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_w1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_b1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_w2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_b2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mopinion1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrust1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvopinion1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_w1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_b1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;31m#         print(np.isnan(np.min(opinion1)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\TF2.4.1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1012\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-74-91193512e885>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, input1, input2, input3)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ_trust\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ_trust\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-58d495f0b0fd>\u001b[0m in \u001b[0;36mconv_forward\u001b[1;34m(A_prev, W_w, W_b)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m#             print(a_slice_prev)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m#             print('a_slice_prev :', np.isnan(np.min(a_slice_prev)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mopinion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrust\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_single_step_trust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_slice_prev\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;31m#             print(opinion.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopinion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-71-78eea5cc6ff3>\u001b[0m in \u001b[0;36mconv_single_step_trust\u001b[1;34m(W_x, W_w, W_b)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#     print('W_x_expand',np.isnan(np.min(W_x_expand)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m#     print('W_w_expand',np.isnan(np.min(W_w_expand)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mW_wx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmulti\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW_x_expand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW_w_expand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# (4, 32, 3, 5, 5, 50)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;31m#     print(np.asarray(W_wx)[:])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m#     print(np.isnan(np.min(W_wx)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-70-fdd65b2e7f46>\u001b[0m in \u001b[0;36mmulti\u001b[1;34m(W_x, W_y)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mW_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mW_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#     print(np.isnan(np.min(W_x[0]*W_y[0])))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mW_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mW_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mW_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mW_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mW_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mW_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mW_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mW_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mW_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mW_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mW_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mW_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mW_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#     print(np.isnan(np.min(W_b)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mW_d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mW_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mW_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mW_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mW_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_batches = int(data_loader.num_train_data // batch_size * num_epochs)\n",
    "\n",
    "W_w1 = w_initial1\n",
    "W_b1 = b_initial1\n",
    "W_w2 = w_initial2\n",
    "W_b2 = b_initial2\n",
    "# W_w3 = w_initial3\n",
    "# W_b3 = b_initial3\n",
    "# W_w4 = w_initial4\n",
    "# W_b4 = b_initial4\n",
    "# W_w5 = w_initial5\n",
    "# W_b5 = b_initial5\n",
    "\n",
    "grads_list_w1 = np.zeros((kernelsize,kernelsize,1,filter_num1))\n",
    "grads_list_b1 = np.zeros((filter_num1,))\n",
    "grads_list_w2 = np.zeros((kernelsize,kernelsize,filter_num1,filter_num2))\n",
    "grads_list_b2 = np.zeros((filter_num2,))\n",
    "# grads_list_w3 = np.zeros((kernelsize,kernelsize,filter_num2,filter_num3))\n",
    "# grads_list_b3 = np.zeros((filter_num3,))\n",
    "# grads_list_w4 = np.zeros((784,64))\n",
    "# grads_list_b4 = np.zeros((64,))\n",
    "# grads_list_w5 = np.zeros((64,10))\n",
    "# grads_list_b5 = np.zeros((10,))\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "for batch_index in range(num_batches):\n",
    "    print('# of batch:',batch_index)\n",
    "    X, y = data_loader.get_batch(batch_size)  \n",
    "    W_x ,_ = intitial_opinion_trust(X)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred,opinion_conv1,opinion_conv2,opinion_conv = model([X, W_x, W_w1, W_b1, W_w2, W_b2])\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)\n",
    "        \n",
    "    grads = tape.gradient(loss, model.variables)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "    \n",
    "    sparse_categorical_accuracy.update_state(y_true=y, y_pred=y_pred)\n",
    "    opinion_convlist.append(np.reshape(opinion_conv, (opinion_conv.shape[0], \n",
    "                                                      int(opinion_conv.shape[1]*opinion_conv.shape[2]*opinion_conv.shape[3]),4)))\n",
    "    train_loss.append(tf.reduce_mean(loss).numpy())\n",
    "    train_acc.append(sparse_categorical_accuracy.result().numpy())\n",
    "    print(\"train accuracy:\",sparse_categorical_accuracy.result().numpy())\n",
    "#     print('Model update end:',(time.time()-start))\n",
    "    \n",
    "    \n",
    "# update W_w, W_b\n",
    "    grads_list_w1 = grads_list_w1 + tf.where(abs(grads[0])<threshold1, 1, 0)  #  shape=(5, 5, 3, 8)\n",
    "    grads_list_b1 = grads_list_b1 + tf.where(abs(grads[1])<threshold1, 1, 0)  #  shape=(8,)\n",
    "    grads_list_w2 = grads_list_w2 + tf.where(abs(grads[2])<threshold2, 1, 0)  #  shape=(5, 5, 8, 12)\n",
    "    grads_list_b2 = grads_list_b2 + tf.where(abs(grads[3])<threshold2, 1, 0)  #  shape=(12,)\n",
    "\n",
    "#     print('W_w, W_b update start:',(time.time()-start))  # 20s\n",
    "    \n",
    "    W_w1, W_b1 = get_update_matrix(grads_list_w1, grads_list_b1, batch_index+1)\n",
    "    W_w2, W_b2 = get_update_matrix(grads_list_w2, grads_list_b2, batch_index+1)\n",
    "#     W_w3, W_b3 = get_update_matrix(grads_list_w3, grads_list_b3, batch_index+1)\n",
    "#     W_w4, W_b4 = get_update_matrix(grads_list_w4, grads_list_b4, batch_index+1)\n",
    "#     W_w5, W_b5 = get_update_matrix(grads_list_w5, grads_list_b5, batch_index+1)\n",
    "\n",
    "    y_N_update, y_N_op = evidence_collect(y, y_pred)\n",
    "    \n",
    "    y_N_opinion.append(y_N_op)\n",
    "    y_update_wb.append(y_N_update)\n",
    "\n",
    "    print('One batch end:',(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_variable(v,filename):\n",
    "    f=open(filename,'wb')\n",
    "    pickle.dump(v,f)\n",
    "    f.close()\n",
    "    return filename\n",
    " \n",
    "def load_variavle(filename):\n",
    "    f=open(filename,'rb')\n",
    "    r=pickle.load(f)\n",
    "    f.close()\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('model_max_trust_MINIST1_sub')\n",
    "# save_variable(W_w1, 'max_trust_MINST1_weight_opinion1_sub')\n",
    "# save_variable(W_w2, 'max_trust_MINST1_weight_opinion2_sub')\n",
    "\n",
    "# save_variable(W_b1, 'max_trust_MINIST1_bias_opinion1_sub')\n",
    "# save_variable(W_b2, 'max_trust_MINIST1_bias_opinion2_sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('my_model_max_trust_MINIST')\n",
    "W_w1 = load_variavle('MINST_weight_opinion1')\n",
    "W_w2 = load_variavle('MINST_weight_opinion2')\n",
    "W_b1 = load_variavle('MINIST_bias_opinion1')\n",
    "W_b2 = load_variavle('MINIST_bias_opinion2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "sGew9OE1xVOK",
    "outputId": "59d12435-fc79-4e80-ddb5-e5754206c192"
   },
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "Exception encountered when calling layer \"conv2d_6\" (type Conv2D).\n\nFailed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(10000, 28, 28, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-2e990359274d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_batch_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mW_x\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintitial_opinion_trust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_pred_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_w1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_b1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_w2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_b2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msparse_categorical_accuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msparse_categorical_accuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-64-a9e9c56cb6d9>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mopinion1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrust1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvopinion1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_w1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_b1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;31m#         print(np.isnan(np.min(opinion1)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;31m#         print('Underflow or not: ',np.isnan(np.min(trust1)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Exception encountered when calling layer \"conv2d_6\" (type Conv2D).\n\nFailed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(10000, 28, 28, 1), dtype=float32)"
     ]
    }
   ],
   "source": [
    "X_test, y_test= data_loader.get_batch_test()\n",
    "W_x ,_ = intitial_opinion_trust(X_test)\n",
    "y_pred_test, _,_,_ = model([X_test, W_x, W_w1, W_b1, W_w2, W_b2])\n",
    "sparse_categorical_accuracy.reset_states()\n",
    "sparse_categorical_accuracy.update_state(y_true=y_test, y_pred=y_pred_test)\n",
    "print(\"test accuracy:\",sparse_categorical_accuracy.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "TOopxTrEO4b6",
    "outputId": "158d5df2-337f-44eb-eda3-a5881e38c6b8",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "Exception encountered when calling layer \"conv2d_3\" (type Conv2D).\n\nFailed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(10000, 28, 28, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-19845e0e8bdf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX_test_noise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_noise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_noise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gaussian'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnoise_opinion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintitial_opinion_trust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_noise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0my_pred_test_noise\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopinion_conv1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopinion_conv2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopinion_conv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_test_noise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_opinion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_w1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_b1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_w2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_b2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0msparse_categorical_accuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msparse_categorical_accuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test_noise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred_test_noise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-a9e9c56cb6d9>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mopinion1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrust1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvopinion1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_w1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_b1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;31m#         print(np.isnan(np.min(opinion1)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;31m#         print('Underflow or not: ',np.isnan(np.min(trust1)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Exception encountered when calling layer \"conv2d_3\" (type Conv2D).\n\nFailed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(10000, 28, 28, 1), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# test noisy dataset\n",
    "X_test_noise, y_test_noise = data_loader.get_noise('gaussian')\n",
    "noise_opinion,_ = intitial_opinion_trust(X_test_noise)\n",
    "y_pred_test_noise,opinion_conv1,opinion_conv2,opinion_conv = model([X_test_noise, noise_opinion, W_w1, W_b1, W_w2, W_b2])\n",
    "sparse_categorical_accuracy.reset_states()\n",
    "sparse_categorical_accuracy.update_state(y_true=y_test_noise, y_pred=y_pred_test_noise)\n",
    "print(\"test accuracy:\",sparse_categorical_accuracy.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ed7fd3dbaf9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# test localvar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_test_local_noise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_local_noise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcase1_opinion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_local_noise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcase2_opinion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintitial_W_x_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_local_noise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcase3_opinion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintitial_W_x\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_local_noise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_pred_test_local_noise\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopinion_noise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_test_local_noise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcase1_opinion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_w1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_b1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_w2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_b2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# test localvar\n",
    "X_test_local_noise, y_test_local_noise, case1_opinion, noise_index = data_loader.get_local_noise()\n",
    "case2_opinion = intitial_W_x_location(X_test_local_noise, noise_index)\n",
    "case3_opinion = intitial_W_x(X_test_local_noise)\n",
    "y_pred_test_local_noise,_,_,opinion_noise = model([X_test_local_noise, case1_opinion, W_w1, W_b1, W_w2, W_b2])\n",
    "sparse_categorical_accuracy.reset_states()\n",
    "sparse_categorical_accuracy.update_state(y_true=y_test_local_noise, y_pred=y_pred_test_local_noise)\n",
    "print(\"test accuracy:\",sparse_categorical_accuracy.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.moments(tf.constant([0.7659,0.5648,0.573,0.9616,0.9515]),axes=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NN_trust(opinion_last_layer, true_label, pre_label, y_update_wb):\n",
    "    # compute dense opinion\n",
    "    opinion_dense = np.average(np.array(opinion_last_layer), axis=0)\n",
    "    opinion_dense = np.reshape(opinion_dense, \n",
    "                                     (int(opinion_dense.shape[0]*opinion_dense.shape[1]*opinion_dense.shape[2]),4))\n",
    "    y_true_op = [1.0, 0.0, 0.0, 0.5]\n",
    "    W_y_update = evidence_collect_test(true_label, pre_label)\n",
    "    \n",
    "    # compute Backward opinion of neuron W_N_Y  \n",
    "    W_N_Y=[]\n",
    "    for j in W_y_update:\n",
    "        W_N_Y.append(multi(j,y_true_op)) # change when add flaw in label\n",
    "        \n",
    "    W_w_dense = y_update_wb[-1]\n",
    "    W_b_dense = y_update_wb[-1]\n",
    "\n",
    "    W_xw=[]\n",
    "    W_xw.append(W_b_dense)\n",
    "    for j in range(opinion_dense.shape[0]):\n",
    "        W_xw.append(multi(W_w_dense,opinion_dense[j])) # (513, 4)\n",
    "    dense_out = fusion(np.array(W_xw))\n",
    "    #     print('Underflow or not: ',np.isnan(np.min(np.array(dense1_out_list))))\n",
    "\n",
    "    # last layer\n",
    "    W_xw=[]\n",
    "    W_xw.append(W_b_dense)\n",
    "    for j in range(64):\n",
    "        W_xw.append(multi(W_w_dense,dense_out))\n",
    "    W_NN = fusion(np.array(W_xw))\n",
    "    \n",
    "    # compute last layer output opinion and trust\n",
    "    W_XY_one = []\n",
    "    for j in range(10):\n",
    "        W_XY_one.append(fusion_2(W_NN,W_N_Y[j]))\n",
    "    W_NN = fusion(np.array(W_XY_one))\n",
    "    W_trust = W_NN[0]+W_NN[2]*W_NN[3]\n",
    "    \n",
    "    return W_trust, W_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FybnpbUYxVOI"
   },
   "outputs": [],
   "source": [
    "# forward opinion prop\n",
    "def mul_scale(W_x):\n",
    "    mul_u = 1.0\n",
    "    for i in range(len(W_x)):\n",
    "        mul_u = mul_u * W_x[i]\n",
    "        if mul_u <= 1e-24: \n",
    "            mul_u = mul_u*1e25\n",
    "    return mul_u\n",
    "\n",
    "def fusion(W_x): # W_x array\n",
    "\n",
    "    deno = 0.0\n",
    "    mole = 0.0\n",
    "    full_multi = mul_scale(W_x[:,2])\n",
    "    for i in range(len(W_x[:,2])):\n",
    "        deno = deno + full_multi/W_x[:,2][i]\n",
    "        mole = mole + (full_multi/W_x[:,2][i])*W_x[:,0][i]\n",
    "    W_b = mole/deno  #  change\n",
    "    W_u = (len(W_x)*full_multi)/deno   # change\n",
    "    W_a = sum(W_x[:,3])/len(W_x)  \n",
    "\n",
    "#     W_b = sum(1/len(W_x)*W_x[:,0])\n",
    "#     W_u = 0.0\n",
    "#     W_a = sum(1/len(W_x)*W_x[:,3])\n",
    "        \n",
    "    return [W_b,1-W_b-W_u,W_u,W_a]\n",
    "\n",
    "def fusion_2(W_x, W_y):\n",
    "    if W_x[2]!=0 or W_y[2]!=0:\n",
    "        W_b = (W_x[0]*W_y[2]+W_y[0]*W_x[2])/(W_x[2]+W_y[2])\n",
    "        W_u = 2*W_x[2]*W_y[2]/(W_x[2]+W_y[2])\n",
    "        W_a = (W_x[3]+W_y[3])/2  \n",
    "    elif W_x[2]==0 and W_y[2]==0:\n",
    "        W_b = 0.5*W_x[0]+0.5*W_y[0]\n",
    "        W_u = 0\n",
    "        W_a = 0.5*W_x[3]+0.5*W_y[3]\n",
    "    return [W_b,1-W_b-W_u,W_u,W_a]\n",
    "\n",
    "def multi(W_x, W_y): # \n",
    "    W_b = W_x[0]*W_y[0]+((1-W_x[3])*W_y[3]*W_x[0]*W_y[2]+W_x[3]*(1-W_y[3])*W_y[0]*W_x[2])/(1-W_x[3]*W_y[3])\n",
    "    W_d = W_x[1]+W_y[1]-W_x[1]*W_y[1]\n",
    "    W_u = W_x[2]*W_y[2]+((1-W_y[3])*W_x[0]*W_y[2]+(1-W_x[3])*W_y[0]*W_x[2])/(1-W_x[3]*W_y[3])\n",
    "    W_a = W_x[3]*W_y[3]\n",
    "    return [W_b,W_d,W_u,W_a]\n",
    "\n",
    "\n",
    "def evidence_collect_test(y, y_pred):\n",
    "    r_list = [0]*10\n",
    "    s_list = [0]*10\n",
    "    index = np.random.randint(0,y.shape[0], 5000)\n",
    "    \n",
    "    for j in index:\n",
    "        for i in range(len(y_pred[0])):\n",
    "            if i == y[j]:\n",
    "                if y_pred[j][i] > 0.9:\n",
    "                    r_list[i]+=1\n",
    "                else:\n",
    "                    s_list[i]+=1\n",
    "            else:\n",
    "                if y_pred[j][i] < 0.1:\n",
    "                    r_list[i]+=1\n",
    "                else:\n",
    "                    s_list[i]+=1\n",
    "                    \n",
    "    y_N_op = []\n",
    "    for i in range(len(r_list)):\n",
    "        y_N_op.append(np.array([r_list[i]/(r_list[i]+s_list[i]+2), \n",
    "                       s_list[i]/(r_list[i]+s_list[i]+2), 2/(r_list[i]+s_list[i]+2), 0.5]))\n",
    "\n",
    "    \n",
    "    return y_N_op\n",
    "\n",
    "# def evidence_collect_test(y, y_pred):\n",
    "#     r_list = 0\n",
    "#     s_list = 0\n",
    "#     index = np.random.randint(0,y.shape[0], 1000)\n",
    "    \n",
    "#     for i in index:\n",
    "#         if np.argmax(y_pred[i]) == y[i]:\n",
    "#             r_list+=1\n",
    "#         else:\n",
    "#             s_list+=1\n",
    "                    \n",
    "#     return np.array([r_list/(r_list+s_list+2), s_list/(r_list+s_list+2), 2/(r_list+s_list+2), 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original image trustworthiness result:',get_NN_trust(opinion_original, y_test, y_pred_test, y_update_wb)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Noise image trustworthiness result:',get_NN_trust(opinion_noise, y_test_noise, y_pred_test_noise, y_update_wb)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6LcVJfx3xVOK"
   },
   "outputs": [],
   "source": [
    "W_y_update = evidence_collect_test(y_test_noise, y_pred_test_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TqNZd2HxVOK"
   },
   "outputs": [],
   "source": [
    "# compute Backward opinion of neuron W_N_Y  \n",
    "W_N_Y_noise=[]\n",
    "for j in W_y_update:\n",
    "    W_N_Y_noise.append(multi(j,y_true_op)) # change when add flaw in label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tXBrgH_rxVOK"
   },
   "outputs": [],
   "source": [
    "opinion_dense_noise = np.average(np.array(opinion_mid), axis=0)\n",
    "opinion_dense_noise = np.reshape(opinion_dense_noise, \n",
    "                                 (int(opinion_dense_noise.shape[0]*opinion_dense_noise.shape[1]*opinion_dense_noise.shape[2]),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFSE0_K0xVOL"
   },
   "outputs": [],
   "source": [
    "W_w_dense = y_update_wb[-1]\n",
    "W_b_dense = y_update_wb[-1]\n",
    "input_dense = opinion_dense_noise\n",
    "\n",
    "W_xw=[]\n",
    "W_xw.append(W_b_dense)\n",
    "for j in range(opinion_dense_noise.shape[0]):\n",
    "    W_xw.append(multi(W_w_dense,input_dense[j]))\n",
    "dense_out_noise = fusion(np.array(W_xw))\n",
    "#     print('Underflow or not: ',np.isnan(np.min(np.array(dense1_out_list))))\n",
    "\n",
    "# last layer\n",
    "W_xw=[]\n",
    "W_xw.append(W_b_dense)\n",
    "for j in range(64):\n",
    "    W_xw.append(multi(W_w_dense,dense_out_noise))\n",
    "W_NN_noise = fusion(np.array(W_xw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7jZ9h3IxVOL"
   },
   "outputs": [],
   "source": [
    "# compute last layer output opinion and trust\n",
    "W_XY_one = []\n",
    "for j in range(10):\n",
    "    W_XY_one.append(fusion_2(W_NN_noise,W_N_Y_noise[j]))\n",
    "\n",
    "W_NN = fusion(np.array(W_XY_one))\n",
    "W_trust = W_NN[0]+W_NN[2]*W_NN[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mpeUgQToxVOL",
    "outputId": "19e6ba2d-52be-454d-8ac5-fdd3e00c2d24",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W_trust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PVDfqwfrxVOL",
    "outputId": "76bce6f9-297c-475a-93f1-8f43a7d64d93"
   },
   "outputs": [],
   "source": [
    "entropy = -1 * (W_trust * np.log2(W_trust) + (1-W_trust) * np.log2(1-W_trust))\n",
    "entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yls_EC7oxVOL"
   },
   "outputs": [],
   "source": [
    "plt.imshow(X_test[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fSYzNaUQxVOL"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "for i in range(1,11):\n",
    "    plt.subplot(1,10,i)\n",
    "    plt.imshow(trust1[0,:,:,i-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jtsl2qAKxVOL"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "for i in range(1,21):\n",
    "    plt.subplot(1,20,i)\n",
    "    plt.imshow(trust2[0,:,:,i-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ANNnXlXxVOL"
   },
   "outputs": [],
   "source": [
    "trust2[0,1,1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FKJvi3SuxVOL"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(1,13):\n",
    "    plt.subplot(1,12,i)\n",
    "    plt.imshow(trust3[0,:,:,i-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6YCh8VjXxVOM"
   },
   "outputs": [],
   "source": [
    "opinion1 = np.moveaxis(opinion1, -1, 0)\n",
    "opinion2 = np.moveaxis(opinion2, -1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tuVFnYxZxVOM"
   },
   "outputs": [],
   "source": [
    "opinion1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XsNvBIMGxVOM"
   },
   "outputs": [],
   "source": [
    "max_trust1 = opinion1[0]+opinion1[2]*opinion1[3]\n",
    "max_trust2 = opinion2[0]+opinion2[2]*opinion2[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "za93xzI-xVOM"
   },
   "outputs": [],
   "source": [
    "max_trust1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cDVtYMEMxVOM"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(1,7):\n",
    "    plt.subplot(1,6,i)\n",
    "    plt.imshow(max_trust1[0,:,:,i-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZsJokfiHxVOM"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(1,13):\n",
    "    plt.subplot(1,12,i)\n",
    "    plt.imshow(max_trust2[0,:,:,i-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ztTfT8va5SGy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MINIST_with_Max_Trust.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
